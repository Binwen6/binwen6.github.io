---
title: "811-817"
description: "Add your description here..."
pubDate: "2025-08-18"
tags: []
---

# 811-817

上周的主要内容集中在Encodec模块技术路径的可行性实践。

## Introduction

1. 使用Maestro-v3.0数据集成功复现了Encodec-pyTorch版本的非官方开源代码
2. 针对Quantizer中包含的参数: Codebook Size和Codebook Layer Number进行了策略性调整与批量对比实验
3. 分析了Codebook容量在重建质量中发挥的作用，并进行了对重建质量影响因素的敏感性分析
4. 首次进行四卡并行训练与推理，熟悉了分布式计算的基本规范

## Main Content

### Maestro-v3.0 Dataset
Maestro数据集是一个包含近1300首高质量古典钢琴乐的数据集，总时长两百余小时。数据格式包括.wav/.mid。  
相比于之前在进行eeg-music reconstruction任务的脑电信号采集阶段使用的Music stimulus，Maestro数据集显然是一个单曲时长更长，质量更高的选择，也因此对我们模型的重建质量提供了更大的发挥空间。

### Encodec-pyTorch
Encodec架构作为Meta发布的一个用于高保真音乐编解码的模型架构，其创新点在于引入了GAN风格的一系列损失函数，并将其通过`Balancer`模块进行了合理的组合，从而在音乐的时域、频域损失，感知质量，可区分度，量化损失程度等方面进行了综合的约束与引导。其另一创新在于引入了RVQ这一巧妙的量化结构作为进一步压缩量化器体积并减少离散信号冗余度的方法。多层的码本结构类似于一种逐层补偿机制，在逐渐细粒度的量化过程中引导Encoder编码出更容易压缩的Embedding。

对于码本坍塌这一问题，其本质在于编码模态与解码模态间的信息密度差异，或者说码率/带宽的数量级差异。做一道简单的计算题：假如编码模态是以500Hz采样率采样的EEG信号，而解码模态是以22.4kHz/24kHz的音频，那么它们之间的数量级差异就会达到近50倍，而这50倍的信息密度差异足以让我们解码出的音频信号terribly bad。所以，在尽可能保留原始音频结构和保证基本听感的前提下，最大限度地压缩解码模态的码率/带宽是一个显而易见的方式。

于是，我们分别尝试了24kbps/12kbps/6kbps/3kbps/1.5kbps等一系列不同码率的压缩程度，发现在使用3kbps带宽下(也就是4层码本)且每层码本数量为256时，会达到一个不错的trade-off。

## Conclusion

下周的计划是在前期规律及经验总结的基础上，开始正式以eeg信号为出发点的系列实验，采用压缩码本容量的方式去验证减少码本坍塌的可行性。

---

*This post was created using the automated script.*
